{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1tTsNR2zVNR_leyjNfsqjtRuPAChjiD_N","authorship_tag":"ABX9TyP9tZGOvtVqwDfwlCAMAQ9/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0LENrObxIz4B","executionInfo":{"status":"ok","timestamp":1712757827490,"user_tz":-60,"elapsed":13230,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}},"outputId":"210f7ab0-7c7c-4289-ba6e-1d4b7ebb2c94"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"]}],"source":["pip install tensorflow\n"]},{"cell_type":"code","source":["pip install gensim scikit-learn pandas numpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WfXumITUuOXY","executionInfo":{"status":"ok","timestamp":1712757834555,"user_tz":-60,"elapsed":7068,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}},"outputId":"1bfc3a9c-6bc4-42ae-e919-d9162265bdbc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.models import Sequential\n","from keras.regularizers import l2\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, SpatialDropout1D, Conv1D, GlobalMaxPooling1D, SimpleRNN, GlobalAveragePooling1D, Flatten, Concatenate\n","from sklearn.metrics import accuracy_score, classification_report,confusion_matrix,f1_score, precision_score, recall_score\n","from gensim.models import KeyedVectors\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import LinearSVC\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import pickle\n"],"metadata":{"id":"TwJr1G4ZLEdm","executionInfo":{"status":"ok","timestamp":1712757838432,"user_tz":-60,"elapsed":3880,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["**Load the Dataset**"],"metadata":{"id":"KVMaJED-JtQG"}},{"cell_type":"code","source":["# Load the datasets\n","#train_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/train_half.csv')\n","#test_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/test_half.csv')\n","\n","#train_df=pd.read_csv(\"/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/train.csv\")\n","#test_df=pd.read_csv(\"/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/test.csv\")\n"],"metadata":{"id":"OC5kV-TOLTh3","executionInfo":{"status":"ok","timestamp":1712757838432,"user_tz":-60,"elapsed":6,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# ***Predict genre based on song lyrics***"],"metadata":{"id":"STJvL7tB5cBP"}},{"cell_type":"markdown","source":["Preprocessing"],"metadata":{"id":"xj7m-yuGLaZh"}},{"cell_type":"code","source":["def preprocess(train_df, test_df):\n","    # Fill missing 'Lyrics' with empty strings\n","    train_df['Lyrics'] = train_df['Lyrics'].fillna(\"\")\n","    test_df['Lyrics'] = test_df['Lyrics'].fillna(\"\")\n","\n","    # Drop rows where 'Lyrics' or 'Genre' is missing in the training set, and 'Lyrics' is missing in the test set\n","    train_df.dropna(subset=[\"Lyrics\", \"Genre\"], inplace=True)\n","    test_df.dropna(subset=[\"Lyrics\"], inplace=True)\n","\n","    # Convert 'Lyrics' to lowercase\n","    train_df['Lyrics'] = train_df['Lyrics'].astype(str).str.lower()\n","    test_df['Lyrics'] = test_df['Lyrics'].astype(str).str.lower()\n","\n","    return train_df, test_df"],"metadata":{"id":"guYWv4cvp8kz","executionInfo":{"status":"ok","timestamp":1712757838432,"user_tz":-60,"elapsed":5,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def vectorization(train_df,test_df):\n","  tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n","  train_vec = tfidf_vectorizer.fit_transform(train_df['Lyrics'])\n","  test_vec = tfidf_vectorizer.transform(test_df['Lyrics'])\n","  return train_vec,test_vec"],"metadata":{"id":"fgjtKH53rHZc","executionInfo":{"status":"ok","timestamp":1712757838432,"user_tz":-60,"elapsed":5,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def enc(train_df,test_df):\n","  label_encoder=LabelEncoder()\n","  train_encoded_labels=label_encoder.fit_transform(train_df[\"Genre\"])\n","  test_encoded_labels=label_encoder.transform(test_df[\"Genre\"])\n","  return train_encoded_labels,test_encoded_labels"],"metadata":{"id":"ls0Bfm1Mt0Km","executionInfo":{"status":"ok","timestamp":1712757838432,"user_tz":-60,"elapsed":5,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def encoding(train_df,test_df):\n","  label_encoder = LabelEncoder()\n","  train_encoded_labels = label_encoder.fit_transform(train_df[\"Genre\"])\n","  train_labels = to_categorical(train_encoded_labels)\n","\n","   #num_classes = np.max(train_labels) + 1\n","  test_encoded_labels=label_encoder.transform(test_df['Genre'])\n","  test_labels = to_categorical(test_encoded_labels)\n","  return train_labels,test_labels,label_encoder"],"metadata":{"id":"9kLGGUqRrUvB","executionInfo":{"status":"ok","timestamp":1712757838432,"user_tz":-60,"elapsed":5,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def tokenizing(train_df,test_df):\n","  # Tokenize and pad the sequences\n","  tokenizer = Tokenizer()\n","  tokenizer.fit_on_texts(train_df['Lyrics'])\n","  max_length = max(max(len(s.split()) for s in train_df['Lyrics']), max(len(s.split()) for s in test_df['Lyrics']))\n","  vocab_size = len(tokenizer.word_index) + 1\n","\n","  train_sequences = tokenizer.texts_to_sequences(train_df['Lyrics'])\n","  train_data = pad_sequences(train_sequences, maxlen=max_length)\n","  test_sequences = tokenizer.texts_to_sequences(test_df['Lyrics'])\n","  test_data = pad_sequences(test_sequences, maxlen=max_length)\n","  return train_data,test_data,max_length,vocab_size"],"metadata":{"id":"V1tq9EnHrnEo","executionInfo":{"status":"ok","timestamp":1712757838432,"user_tz":-60,"elapsed":5,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def document_vector(word2vec_model, doc):\n","    doc = [word for word in doc.split() if word in word2vec_model.key_to_index]\n","    if not doc:\n","        return np.zeros(word2vec_model.vector_size)\n","    return np.mean(word2vec_model[doc], axis=0)"],"metadata":{"id":"WAcOtRwJ8WJT","executionInfo":{"status":"ok","timestamp":1712757838433,"user_tz":-60,"elapsed":6,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["**SVM**"],"metadata":{"id":"Fq2xqqwsoJAs"}},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/Part1_train.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/test_half.csv')\n","\n","train_df,test_df=preprocess(train_df,test_df)\n","train_encoded_labels,test_encoded_labels=enc(train_df,test_df)\n","train_vec,test_vec=vectorization(train_df,test_df)\n","\n","svm_classifier = LinearSVC(C=1.0, random_state=42)\n","\n","#lr= LogisticRegression(max_iter=1000)\n","svm_classifier.fit(train_vec,train_encoded_labels)\n","\n","y_pred = svm_classifier.predict(test_vec)\n","accuracy = accuracy_score(test_encoded_labels, y_pred)\n","print(\"Accuracy \",accuracy)\n","# Evaluate the model\n","cm = confusion_matrix(test_encoded_labels, y_pred)\n","print(\"Confusion matrix\",cm)\n","print(\"Validation Set Performance:\")\n","print(classification_report(test_encoded_labels, y_pred))\n","\n","\n","#Save the model\n","model_file=\"/content/drive/MyDrive/Deep_Learning_Assignment/saved_models/svm.pkl\"\n","with open(model_file,'wb') as f:\n","  pickle.dump(svm_classifier,f)\n","\n","print(\"Model saved\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pTVQ1rBdoIlH","executionInfo":{"status":"ok","timestamp":1712757838433,"user_tz":-60,"elapsed":5,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}},"outputId":"d1eaa6ab-3b20-4e79-eb68-a4aff3b3f828"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy  0.38461538461538464\n","Confusion matrix [[0 4 0]\n"," [0 3 1]\n"," [0 3 2]]\n","Validation Set Performance:\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00         4\n","           1       0.30      0.75      0.43         4\n","           2       0.67      0.40      0.50         5\n","\n","    accuracy                           0.38        13\n","   macro avg       0.32      0.38      0.31        13\n","weighted avg       0.35      0.38      0.32        13\n","\n","Model saved\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","source":["**RNN**"],"metadata":{"id":"YfGgJm-sJzvp"}},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/Part1_train.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/test_half.csv')\n","\n","train_df,test_df=preprocess(train_df,test_df)\n","train_labels,test_labels,label_encoder=encoding(train_df,test_df)\n","train_data,test_data,max_length,vocab_size=tokenizing(train_df,test_df)\n","\n","num_classes = train_labels.shape[1]\n","rnn_model = Sequential([\n","    Embedding(input_dim=vocab_size, output_dim=50, input_length=max_length),\n","    SimpleRNN(64, return_sequences=False),\n","    Dense(num_classes, activation='softmax')\n","])\n","\n","rnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","rnn_model.summary()\n","#train the model\n","rnn=rnn_model.fit(train_data, train_labels, epochs=5,batch_size=32,validation_split=0.2)\n","#find the F1 score\n","y_pred_prob=rnn_model.predict(test_data)\n","y_pred=np.argmax(y_pred_prob,axis=1)\n","y_true=np.argmax(test_labels,axis=1)\n","f1=f1_score(y_true,y_pred,average='weighted')\n","print(f\"F1 score:{f1}\")\n","# Calculate Precision and Recall\n","precision = precision_score(y_true, y_pred, average='weighted')\n","recall = recall_score(y_true, y_pred, average='weighted')\n","\n","print(f'Precision: {precision}')\n","print(f'Recall: {recall}')\n","\n","#check the accuracy\n","lo, acc = rnn_model.evaluate(test_data, test_labels)\n","print(f'Test accuracy: {acc}')\n","print(f'Loss:{lo}')\n","#Save the model\n","rnn_model.save(\"/content/drive/MyDrive/Deep_Learning_Assignment/saved_models/RNN_new_model.h5\")\n","print(\"RNN Model saved\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LuX05kmmNQUV","executionInfo":{"status":"ok","timestamp":1712760170793,"user_tz":-60,"elapsed":144938,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}},"outputId":"d6b8cae0-3d19-421d-ca1f-c996dc9aeec1"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_15 (Embedding)    (None, 868, 50)           382250    \n","                                                                 \n"," simple_rnn_3 (SimpleRNN)    (None, 64)                7360      \n","                                                                 \n"," dense_20 (Dense)            (None, 3)                 195       \n","                                                                 \n","=================================================================\n","Total params: 389805 (1.49 MB)\n","Trainable params: 389805 (1.49 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/5\n","19/19 [==============================] - 18s 887ms/step - loss: 0.9559 - accuracy: 0.4975 - val_loss: 0.8351 - val_accuracy: 0.2252\n","Epoch 2/5\n","19/19 [==============================] - 16s 861ms/step - loss: 0.7758 - accuracy: 0.6849 - val_loss: 0.7792 - val_accuracy: 0.2848\n","Epoch 3/5\n","19/19 [==============================] - 18s 962ms/step - loss: 0.6266 - accuracy: 0.8491 - val_loss: 0.8526 - val_accuracy: 0.4040\n","Epoch 4/5\n","19/19 [==============================] - 17s 898ms/step - loss: 0.4187 - accuracy: 0.9370 - val_loss: 0.8370 - val_accuracy: 0.5430\n","Epoch 5/5\n","19/19 [==============================] - 18s 933ms/step - loss: 0.1985 - accuracy: 0.9751 - val_loss: 0.9381 - val_accuracy: 0.4901\n","1/1 [==============================] - 0s 191ms/step\n","F1 score:0.34294871794871795\n","Precision: 0.32867132867132864\n","Recall: 0.46153846153846156\n","1/1 [==============================] - 0s 78ms/step - loss: 1.2340 - accuracy: 0.4615\n","Test accuracy: 0.4615384638309479\n","Loss:1.234043002128601\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["RNN Model saved\n"]}]},{"cell_type":"markdown","source":["**LSTM**"],"metadata":{"id":"l2IeQHJ1KIZz"}},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/Part1_train.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/test_half.csv')\n","\n","train_df,test_df=preprocess(train_df,test_df)\n","train_labels,test_labels,label_encoder=encoding(train_df,test_df)\n","train_data,test_data,max_length,vocab_size=tokenizing(train_df,test_df)\n","\n","lstm_model = Sequential([\n","    Embedding(input_dim=vocab_size,output_dim=100, input_length=max_length),\n","    SpatialDropout1D(0.2),\n","    LSTM(100, dropout=0.2,recurrent_dropout=0.2, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01)),\n","    Dense(len(label_encoder.classes_), activation='softmax',kernel_regularizer=l2(0.01))\n","])\n","lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","lstm_model.summary()\n","#train the model\n","lstm=lstm_model.fit(train_data,train_labels, epochs=5, batch_size=32, validation_split=0.2, verbose=2)\n","#find the F1 score\n","y_pred_prob=lstm_model.predict(test_data)\n","y_pred=np.argmax(y_pred_prob,axis=1)\n","y_true=np.argmax(test_labels,axis=1)\n","f1=f1_score(y_true,y_pred,average='weighted')\n","print(f\"F1 score:{f1}\")\n","\n","# Calculate Precision and Recall\n","precision = precision_score(y_true, y_pred, average='weighted')\n","recall = recall_score(y_true, y_pred, average='weighted')\n","\n","print(f'Precision: {precision}')\n","print(f'Recall: {recall}')\n","#check the accuracy\n","test_loss, test_accuracy = lstm_model.evaluate(test_data, test_labels)\n","print(f'Test accuracy: {test_accuracy}')\n","print(f'Loss:{test_loss}')\n","#Save the model\n","lstm_model.save(\"/content/drive/MyDrive/Deep_Learning_Assignment/saved_models/LSTM_model.h5\")\n","print(\"LSTM Model saved\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B3l5qzvxLvrI","executionInfo":{"status":"ok","timestamp":1712759927776,"user_tz":-60,"elapsed":327013,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}},"outputId":"0b38cde2-7f00-4aaa-f73e-63193567d5ff"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_14 (Embedding)    (None, 868, 100)          764500    \n","                                                                 \n"," spatial_dropout1d_1 (Spati  (None, 868, 100)          0         \n"," alDropout1D)                                                    \n","                                                                 \n"," lstm_5 (LSTM)               (None, 100)               80400     \n","                                                                 \n"," dense_19 (Dense)            (None, 3)                 303       \n","                                                                 \n","=================================================================\n","Total params: 845203 (3.22 MB)\n","Trainable params: 845203 (3.22 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/5\n","19/19 - 64s - loss: 3.0994 - accuracy: 0.4726 - val_loss: 2.1256 - val_accuracy: 0.9404 - 64s/epoch - 3s/step\n","Epoch 2/5\n","19/19 - 59s - loss: 2.0273 - accuracy: 0.5041 - val_loss: 1.6723 - val_accuracy: 0.0596 - 59s/epoch - 3s/step\n","Epoch 3/5\n","19/19 - 60s - loss: 1.4965 - accuracy: 0.5804 - val_loss: 1.2477 - val_accuracy: 0.1788 - 60s/epoch - 3s/step\n","Epoch 4/5\n","19/19 - 60s - loss: 1.1926 - accuracy: 0.7214 - val_loss: 1.1891 - val_accuracy: 0.0662 - 60s/epoch - 3s/step\n","Epoch 5/5\n","19/19 - 59s - loss: 0.9893 - accuracy: 0.6434 - val_loss: 1.2484 - val_accuracy: 0.1589 - 59s/epoch - 3s/step\n","1/1 [==============================] - 0s 409ms/step\n","F1 score:0.22624434389140274\n","Precision: 0.16025641025641027\n","Recall: 0.38461538461538464\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 236ms/step - loss: 1.5719 - accuracy: 0.3846\n","Test accuracy: 0.38461539149284363\n","Loss:1.5718786716461182\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Model saved\n"]}]},{"cell_type":"markdown","source":["**CNN**"],"metadata":{"id":"rED3CU5gKNzG"}},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/Part1_train.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/test_half.csv')\n","\n","train_df,test_df=preprocess(train_df,test_df)\n","train_labels,test_labels,label_encoder=encoding(train_df,test_df)\n","train_data,test_data,max_length,vocab_size=tokenizing(train_df,test_df)\n","\n","cnn_model = Sequential([\n","    Embedding(input_dim=vocab_size, output_dim=100, input_length=max_length),\n","    Conv1D(filters=128, kernel_size=5, activation='relu'),\n","    GlobalMaxPooling1D(),\n","    Dense(units=10, activation='relu'),\n","    Dense(units=len(label_encoder.classes_), activation='softmax')\n","])\n","cnn_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n","cnn_model.summary()\n","#train the model\n","cnn= cnn_model.fit(train_data,train_labels, epochs=5, batch_size=32, validation_split=0.2, verbose=2)\n","#find the F1 score\n","y_pred_prob=cnn_model.predict(test_data)\n","y_pred=np.argmax(y_pred_prob,axis=1)\n","y_true=np.argmax(test_labels,axis=1)\n","f1=f1_score(y_true,y_pred,average='weighted')\n","print(f\"F1 score:{f1}\")\n","\n","# Calculate Precision and Recall\n","precision = precision_score(y_true, y_pred, average='weighted')\n","recall = recall_score(y_true, y_pred, average='weighted')\n","\n","print(f'Precision: {precision}')\n","print(f'Recall: {recall}')\n","\n","#check the accuracy\n","test_loss, test_accuracy = cnn_model.evaluate(test_data, test_labels)\n","print(f'Test accuracy: {test_accuracy}')\n","print(f'Loss:{test_loss}')\n","#save the model\n","cnn_model.save(\"/content/drive/MyDrive/Deep_Learning_Assignment/saved_models/CNN_model.h5\")\n","print(\"CNN Model saved\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BFX7hgJzMp_0","executionInfo":{"status":"ok","timestamp":1712760346721,"user_tz":-60,"elapsed":22778,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}},"outputId":"7e20fd17-d779-4441-c0a3-dfa5f4a5b8ec"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_16 (Embedding)    (None, 868, 100)          764500    \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 864, 128)          64128     \n","                                                                 \n"," global_max_pooling1d_3 (Gl  (None, 128)               0         \n"," obalMaxPooling1D)                                               \n","                                                                 \n"," dense_21 (Dense)            (None, 10)                1290      \n","                                                                 \n"," dense_22 (Dense)            (None, 3)                 33        \n","                                                                 \n","=================================================================\n","Total params: 829951 (3.17 MB)\n","Trainable params: 829951 (3.17 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/5\n","19/19 - 4s - loss: 0.9996 - accuracy: 0.4842 - val_loss: 1.0766 - val_accuracy: 0.0596 - 4s/epoch - 222ms/step\n","Epoch 2/5\n","19/19 - 2s - loss: 0.8118 - accuracy: 0.5075 - val_loss: 0.8697 - val_accuracy: 0.0795 - 2s/epoch - 104ms/step\n","Epoch 3/5\n","19/19 - 2s - loss: 0.6791 - accuracy: 0.8972 - val_loss: 0.7208 - val_accuracy: 0.5497 - 2s/epoch - 96ms/step\n","Epoch 4/5\n","19/19 - 2s - loss: 0.5656 - accuracy: 0.9569 - val_loss: 0.6707 - val_accuracy: 0.6887 - 2s/epoch - 89ms/step\n","Epoch 5/5\n","19/19 - 2s - loss: 0.4259 - accuracy: 0.9569 - val_loss: 0.6602 - val_accuracy: 0.6358 - 2s/epoch - 92ms/step\n","1/1 [==============================] - 0s 63ms/step\n","F1 score:0.25384615384615383\n","Precision: 0.2161172161172161\n","Recall: 0.3076923076923077\n","1/1 [==============================] - 0s 24ms/step - loss: 1.5587 - accuracy: 0.3077\n","Test accuracy: 0.3076923191547394\n","Loss:1.5586867332458496\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["CNN Model saved\n"]}]},{"cell_type":"markdown","source":["**Embedding on the fly**"],"metadata":{"id":"ItX8UVwEl8BR"}},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/Part1_train.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/test_half.csv')\n","\n","train_df,test_df=preprocess(train_df,test_df)\n","train_labels,test_labels,label_encoder=encoding(train_df,test_df)\n","train_data,test_data,max_length,vocab_size=tokenizing(train_df,test_df)\n","\n","max_features = 5000\n","maxlen = 400\n","embedding_dims = 50\n","\n","emb_model = Sequential()\n","embedding_size=8\n","emb_model.add(Embedding(max_features,embedding_size,input_length=max_length))\n","emb_model.add(Flatten())\n","emb_model.add(Dense(200, activation='relu'))\n","emb_model.add(Dense(3,activation='softmax'))\n","\n","emb_model.summary()\n","\n","emb_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","emb = emb_model.fit(train_data, train_labels,batch_size=32,epochs=5,validation_split=0.2)\n","\n","#find the F1 score\n","y_pred_prob=emb_model.predict(test_data)\n","y_pred=np.argmax(y_pred_prob,axis=1)\n","y_true=np.argmax(test_labels,axis=1)\n","f1=f1_score(y_true,y_pred,average='weighted')\n","print(f\"F1 score:{f1}\")\n","\n","# Calculate Precision and Recall\n","precision = precision_score(y_true, y_pred, average='weighted')\n","recall = recall_score(y_true, y_pred, average='weighted')\n","\n","print(f'Precision: {precision}')\n","print(f'Recall: {recall}')\n","\n","#check the accuracy\n","test_loss, test_accuracy = emb_model.evaluate(test_data, test_labels)\n","print(f'Test accuracy: {test_accuracy}')\n","print(f'Loss:{test_loss}')\n","\n","#Save the model\n","emb_model.save(\"/content/drive/MyDrive/Deep_Learning_Assignment/saved_models/emb_model.h5\")\n","print(\"Embedding on the fly Model saved\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lVvIxXpfmCIg","executionInfo":{"status":"ok","timestamp":1712758325604,"user_tz":-60,"elapsed":22363,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}},"outputId":"2d1f6f19-482f-473f-a12e-3dd8a77e23b2"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_3 (Embedding)     (None, 868, 8)            40000     \n","                                                                 \n"," flatten (Flatten)           (None, 6944)              0         \n","                                                                 \n"," dense_4 (Dense)             (None, 200)               1389000   \n","                                                                 \n"," dense_5 (Dense)             (None, 3)                 603       \n","                                                                 \n","=================================================================\n","Total params: 1429603 (5.45 MB)\n","Trainable params: 1429603 (5.45 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/5\n","19/19 [==============================] - 5s 194ms/step - loss: 0.8458 - accuracy: 0.4776 - val_loss: 0.8776 - val_accuracy: 0.0596\n","Epoch 2/5\n","19/19 [==============================] - 3s 155ms/step - loss: 0.7118 - accuracy: 0.6750 - val_loss: 0.8718 - val_accuracy: 0.0993\n","Epoch 3/5\n","19/19 [==============================] - 3s 139ms/step - loss: 0.5053 - accuracy: 0.9221 - val_loss: 0.7154 - val_accuracy: 0.5762\n","Epoch 4/5\n","19/19 [==============================] - 2s 129ms/step - loss: 0.2835 - accuracy: 0.9519 - val_loss: 0.5644 - val_accuracy: 0.7748\n","Epoch 5/5\n","19/19 [==============================] - 3s 137ms/step - loss: 0.1395 - accuracy: 0.9735 - val_loss: 0.6058 - val_accuracy: 0.6954\n","1/1 [==============================] - 0s 50ms/step\n","F1 score:0.3153846153846154\n","Precision: 0.2673992673992674\n","Recall: 0.38461538461538464\n","1/1 [==============================] - 0s 23ms/step - loss: 1.9170 - accuracy: 0.3846\n","Test accuracy: 0.38461539149284363\n","Loss:1.917025089263916\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Embedding on the fly Model saved\n"]}]},{"cell_type":"markdown","source":["**Pretrained word embedding**"],"metadata":{"id":"Vyk53jhPmNgL"}},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/Part1_train.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/test_half.csv')\n","\n","train_df,test_df=preprocess(train_df,test_df)\n","train_labels,test_labels,label_encoder=encoding(train_df,test_df)\n","train_data,test_data,max_length,vocab_size=tokenizing(train_df,test_df)\n","\n","word2vec_path = '/content/drive/MyDrive/Deep_Learning_Assignment/saved_models/GoogleNews-vectors-negative300.bin'  # Example for the same directory; adjust as needed\n","word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n","#def document_vector(word2vec_model, doc):\n","#    doc = [word for word in doc.split() if word in word2vec_model.key_to_index]\n","#    if not doc:\n","#        return np.zeros(word2vec_model.vector_size)\n","#    return np.mean(word2vec_model[doc], axis=0)\n","\n","train_df['vec'] = train_df['Lyrics'].apply(lambda x: document_vector(word2vec, x))\n","test_df['vec']=test_df[\"Lyrics\"].apply(lambda x: document_vector(word2vec, x))\n","\n","X = np.array(train_df['vec'].tolist())\n","y = np.array(test_df['vec'].tolist())\n","\n","\n","pre_model = Sequential()\n","#No need for an embedding layer\n","pre_model.add(Dense(200, activation='relu',input_shape=(300,)))\n","pre_model.add(Dense(3,activation='softmax'))\n","\n","pre_model.summary()\n","\n","pre_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","pre = pre_model.fit(X, train_labels,batch_size=32,epochs=3,validation_split=0.2)\n","\n","#find the F1 score\n","y_pred_prob=emb_model.predict(test_data)\n","y_pred=np.argmax(y_pred_prob,axis=1)\n","y_true=np.argmax(test_labels,axis=1)\n","f1=f1_score(y_true,y_pred,average='weighted')\n","print(f\"F1 score:{f1}\")\n","\n","# Calculate Precision and Recall\n","precision = precision_score(y_true, y_pred, average='weighted')\n","recall = recall_score(y_true, y_pred, average='weighted')\n","\n","print(f'Precision: {precision}')\n","print(f'Recall: {recall}')\n","\n","#check the accuracy\n","test_loss, test_accuracy = pre_model.evaluate(y, test_labels)\n","print(f'Test accuracy: {test_accuracy}')\n","print(f'Loss:{test_loss}')\n","\n","#Save the model\n","pre_model.save(\"/content/drive/MyDrive/Deep_Learning_Assignment/saved_models/pre_model.h5\")\n","print(\"Pretrained word Model saved\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Z0x0uNEmQi3","executionInfo":{"status":"ok","timestamp":1712758402695,"user_tz":-60,"elapsed":77108,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}},"outputId":"69dbdc42-d2fc-4723-81a5-e92a70d95a0c"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_6 (Dense)             (None, 200)               60200     \n","                                                                 \n"," dense_7 (Dense)             (None, 3)                 603       \n","                                                                 \n","=================================================================\n","Total params: 60803 (237.51 KB)\n","Trainable params: 60803 (237.51 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/3\n","19/19 [==============================] - 1s 13ms/step - loss: 0.9196 - accuracy: 0.4776 - val_loss: 0.7408 - val_accuracy: 0.8146\n","Epoch 2/3\n","19/19 [==============================] - 0s 5ms/step - loss: 0.7952 - accuracy: 0.6650 - val_loss: 0.8122 - val_accuracy: 0.1523\n","Epoch 3/3\n","19/19 [==============================] - 0s 5ms/step - loss: 0.7709 - accuracy: 0.6750 - val_loss: 0.6915 - val_accuracy: 0.7616\n","1/1 [==============================] - 0s 19ms/step\n","F1 score:0.3153846153846154\n","Precision: 0.2673992673992674\n","Recall: 0.38461538461538464\n","1/1 [==============================] - 0s 22ms/step - loss: 1.5275 - accuracy: 0.3077\n","Test accuracy: 0.3076923191547394\n","Loss:1.5274726152420044\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Pretrained word Model saved\n"]}]},{"cell_type":"markdown","source":["**Pretrained word embedding and logisitic regression**"],"metadata":{"id":"f8cyspHbmaNo"}},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/Part1_train.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/test_half.csv')\n","\n","train_df,test_df=preprocess(train_df,test_df)\n","train_labels,test_labels,label_encoder=encoding(train_df,test_df)\n","train_data,test_data,max_length,vocab_size=tokenizing(train_df,test_df)\n","\n","#!unzip '/content/drive/MyDrive/Deep_Learning_Assignment/saved_models/GoogleNews-vectors-negative300.bin.zip' -d '/content/drive/MyDrive/Deep_Learning_Assignment/saved_models/'\n","word2vec_path = '/content/drive/MyDrive/Deep_Learning_Assignment/saved_models/GoogleNews-vectors-negative300.bin'  # Example for the same directory; adjust as needed\n","word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n","#def document_vector(word2vec_model, doc):\n","#    doc = [word for word in doc.split() if word in word2vec_model.key_to_index]\n","#    if not doc:\n","#        return np.zeros(word2vec_model.vector_size)\n","#    return np.mean(word2vec_model[doc], axis=0)\n","\n","train_df['vec'] = train_df['Lyrics'].apply(lambda x: document_vector(word2vec, x))\n","test_df['vec']=test_df[\"Lyrics\"].apply(lambda x: document_vector(word2vec, x))\n","\n","X = np.array(train_df['vec'].tolist())\n","y = np.array(test_df['vec'].tolist())\n","\n","#lr_model = LogisticRegression(max_iter=1000)\n","#lr_model.fit(X,train_encoded_labels)\n","\n","svm = LinearSVC(C=1.0, random_state=42)\n","\n","#lr= LogisticRegression(max_iter=1000)\n","svm.fit(X,train_encoded_labels)\n","y_pred = svm.predict(y)\n","accuracy = accuracy_score(test_encoded_labels, y_pred)\n","print(\"Accuracy \",accuracy)\n","# Evaluate the model\n","cm = confusion_matrix(test_encoded_labels, y_pred)\n","print(\"Confusion matrix\",cm)\n","print(\"Validation Set Performance:\")\n","print(classification_report(test_encoded_labels, y_pred))\n","\n","\n","#Save the model\n","model_file=\"/content/drive/MyDrive/Deep_Learning_Assignment/saved_models/l_reg.pkl\"\n","with open(model_file,'wb') as f:\n","  pickle.dump(svm,f)\n","\n","print(\"Model saved\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JFQv6DQ1miF_","executionInfo":{"status":"ok","timestamp":1712758441099,"user_tz":-60,"elapsed":38406,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}},"outputId":"5cf4c1dc-ed63-42a3-a077-d47575e6a5b2"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy  0.38461538461538464\n","Confusion matrix [[0 3 1]\n"," [0 3 1]\n"," [0 3 2]]\n","Validation Set Performance:\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00         4\n","           1       0.33      0.75      0.46         4\n","           2       0.50      0.40      0.44         5\n","\n","    accuracy                           0.38        13\n","   macro avg       0.28      0.38      0.30        13\n","weighted avg       0.29      0.38      0.31        13\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Model saved\n"]}]},{"cell_type":"markdown","source":["# ***Predict genre based on song lyrics and artist***"],"metadata":{"id":"DO7criZD5mbp"}},{"cell_type":"code","source":["def preprocess_2(train_df, test_df):\n","    # Fill missing 'Lyrics' with empty strings\n","    train_df['Lyrics'] = train_df['Lyrics'].fillna(\"\")\n","    test_df['Lyrics'] = test_df['Lyrics'].fillna(\"\")\n","    train_df[\"Artist\"]=train_df[\"Artist\"].fillna(\"\")\n","    test_df[\"Artist\"]=test_df[\"Artist\"].fillna(\"\")\n","\n","    # Drop rows where 'Lyrics' or 'Genre' is missing in the training set, and 'Lyrics' is missing in the test set\n","    train_df.dropna(subset=[\"Lyrics\",\"Artist\",\"Genre\"], inplace=True)\n","    test_df.dropna(subset=[\"Lyrics\",\"Artist\"], inplace=True)\n","\n","\n","    # Convert 'Lyrics' to lowercase\n","    train_df['Lyrics'] = train_df['Lyrics'].astype(str).str.lower()\n","    test_df['Lyrics'] = test_df['Lyrics'].astype(str).str.lower()\n","    train_df['Artist'] = train_df['Artist'].astype(str).str.lower()\n","    test_df['Artist'] = test_df['Artist'].astype(str).str.lower()\n","    return train_df, test_df"],"metadata":{"id":"0-OyoDdY5wWB","executionInfo":{"status":"ok","timestamp":1712758441511,"user_tz":-60,"elapsed":415,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def vectorization_2(train_df,test_df):\n","  # Combine 'Lyrics' and 'Artist' into a single string per row for both train and test DataFrames\n","  train_combined = train_df['Lyrics'] + \" \" + train_df['Artist']\n","  test_combined = test_df['Lyrics'] + \" \" + test_df['Artist']\n","  tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n","  train_vec = tfidf_vectorizer.fit_transform(train_combined)\n","  test_vec = tfidf_vectorizer.transform(test_combined)\n","  return train_vec,test_vec"],"metadata":{"id":"KfGadA5h5z9Z","executionInfo":{"status":"ok","timestamp":1712758441511,"user_tz":-60,"elapsed":5,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def enc_2(train_df,test_df):\n","  label_encoder=LabelEncoder()\n","  train_encoded_labels=label_encoder.fit_transform(train_df[\"Genre\"])\n","  test_encoded_labels=label_encoder.transform(test_df[\"Genre\"])\n","  return train_encoded_labels,test_encoded_labels"],"metadata":{"id":"ZaNtEXm151xW","executionInfo":{"status":"ok","timestamp":1712758441511,"user_tz":-60,"elapsed":5,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def encoding_2(train_df,test_df):\n","  label_encoder = LabelEncoder()\n","  train_encoded_labels = label_encoder.fit_transform(train_df[\"Genre\"])\n","  train_labels = to_categorical(train_encoded_labels)\n","\n","   #num_classes = np.max(train_labels) + 1\n","  test_encoded_labels=label_encoder.transform(test_df['Genre'])\n","  test_labels = to_categorical(test_encoded_labels)\n","  return train_labels,test_labels,label_encoder"],"metadata":{"id":"rjX2cNKb53dK","executionInfo":{"status":"ok","timestamp":1712758441511,"user_tz":-60,"elapsed":4,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def tokenizing_2(train_df, test_df):\n","    # Initialize tokenizers\n","    lyrics_tokenizer = Tokenizer()\n","    artist_tokenizer = Tokenizer()\n","\n","    # Fit the tokenizers\n","    lyrics_tokenizer.fit_on_texts(train_df['Lyrics'])\n","    artist_tokenizer.fit_on_texts(train_df['Artist'])\n","\n","    # Find the maximum length for padding\n","    lyrics_max_length = max(max(len(s.split()) for s in train_df['Lyrics']),\n","                            max(len(s.split()) for s in test_df['Lyrics']))\n","    artist_max_length = max(max(len(s.split()) for s in train_df['Artist']),\n","                            max(len(s.split()) for s in test_df['Artist']))\n","\n","    # Vocabulary sizes\n","    lyrics_vocab_size = len(lyrics_tokenizer.word_index) + 1\n","    artist_vocab_size = len(artist_tokenizer.word_index) + 1\n","\n","    # Tokenize and pad the sequences\n","    # Lyrics\n","    train_lyrics_sequences = lyrics_tokenizer.texts_to_sequences(train_df['Lyrics'])\n","    train_lyrics_data = pad_sequences(train_lyrics_sequences, maxlen=lyrics_max_length)\n","    test_lyrics_sequences = lyrics_tokenizer.texts_to_sequences(test_df['Lyrics'])\n","    test_lyrics_data = pad_sequences(test_lyrics_sequences, maxlen=lyrics_max_length)\n","\n","    # Artist\n","    train_artist_sequences = artist_tokenizer.texts_to_sequences(train_df['Artist'])\n","    train_artist_data = pad_sequences(train_artist_sequences, maxlen=artist_max_length)\n","    test_artist_sequences = artist_tokenizer.texts_to_sequences(test_df['Artist'])\n","    test_artist_data = pad_sequences(test_artist_sequences, maxlen=artist_max_length)\n","\n","    return (train_lyrics_data, train_artist_data, test_lyrics_data, test_artist_data,\n","            lyrics_max_length, artist_max_length, lyrics_vocab_size, artist_vocab_size)"],"metadata":{"id":"hyfNIBz8547_","executionInfo":{"status":"ok","timestamp":1712758441511,"user_tz":-60,"elapsed":4,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["***SVM***"],"metadata":{"id":"OZDVeaXJ585P"}},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/Part1_train.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/test_half.csv')\n","\n","train_df,test_df=preprocess_2(train_df,test_df)\n","train_encoded_labels,test_encoded_labels=enc_2(train_df,test_df)\n","train_vec,test_vec=vectorization_2(train_df,test_df)\n","\n","svm_classifier = LinearSVC(C=1.0, random_state=42)\n","\n","#lr= LogisticRegression(max_iter=1000)\n","svm_classifier.fit(train_vec,train_encoded_labels)\n","\n","y_pred = svm_classifier.predict(test_vec)\n","accuracy = accuracy_score(test_encoded_labels, y_pred)\n","print(\"Accuracy \",accuracy)\n","# Evaluate the model\n","cm = confusion_matrix(test_encoded_labels, y_pred)\n","print(\"Confusion matrix\",cm)\n","print(\"Validation Set Performance:\")\n","print(classification_report(test_encoded_labels, y_pred))\n","\n","\n","#Save the model\n","model_file=\"/content/drive/MyDrive/Deep_Learning_Assignment/saved_models/svm.pkl\"\n","with open(model_file,'wb') as f:\n","  pickle.dump(svm_classifier,f)\n","\n","print(\"Model saved\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hCgV3RQ76AGH","executionInfo":{"status":"ok","timestamp":1712758442116,"user_tz":-60,"elapsed":609,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}},"outputId":"91698a6d-dbd1-44c2-cf75-ef33b1542978"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy  0.46153846153846156\n","Confusion matrix [[0 4 0]\n"," [0 3 1]\n"," [0 2 3]]\n","Validation Set Performance:\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00         4\n","           1       0.33      0.75      0.46         4\n","           2       0.75      0.60      0.67         5\n","\n","    accuracy                           0.46        13\n","   macro avg       0.36      0.45      0.38        13\n","weighted avg       0.39      0.46      0.40        13\n","\n","Model saved\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","source":["***RNN***"],"metadata":{"id":"BNwj7dF36C8g"}},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/Part1_train.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/test_half.csv')\n","\n","train_df,test_df=preprocess_2(train_df,test_df)\n","train_labels,test_labels,label_encoder=encoding_2(train_df,test_df)\n","train_lyrics_data, train_artist_data, test_lyrics_data, test_artist_data, lyrics_max_length, artist_max_length, lyrics_vocab_size, artist_vocab_size=tokenizing_2(train_df, test_df)\n","\n","num_classes = train_labels.shape[1]\n","# Define inputs\n","lyrics_input = Input(shape=(lyrics_max_length,), dtype='int32', name='lyrics_input')\n","artist_input = Input(shape=(artist_max_length,), dtype='int32', name='artist_input')\n","\n","# Embeddings\n","lyrics_embedding = Embedding(input_dim=lyrics_vocab_size, output_dim=50, input_length=lyrics_max_length)(lyrics_input)\n","artist_embedding = Embedding(input_dim=artist_vocab_size, output_dim=50, input_length=artist_max_length)(artist_input)\n","\n","# Process Lyrics Embedding\n","lyrics_rnn = SimpleRNN(64)(lyrics_embedding)  # Consider using LSTM or GRU for better performance\n","\n","# Process Artist Embedding\n","artist_rnn = SimpleRNN(64)(artist_embedding)  # Same here, LSTM or GRU could be more appropriate\n","\n","# Merge the outputs from both RNNs\n","merged = Concatenate(axis=-1)([lyrics_rnn, artist_rnn])\n","\n","# Output layer\n","output = Dense(num_classes, activation='softmax')(merged)\n","\n","# Build and compile the model as before\n","rnn_model = Model(inputs=[lyrics_input, artist_input], outputs=output)\n","rnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Now, train the model. Make sure to pass the inputs as a list in the same order as defined.\n","rnn_model.fit([train_lyrics_data, train_artist_data], train_labels, epochs=5, batch_size=32, validation_split=0.2)\n","#find the F1 score\n","y_pred_prob=rnn_model.predict([test_lyrics_data, test_artist_data])\n","y_pred=np.argmax(y_pred_prob,axis=1)\n","y_true=np.argmax(test_labels,axis=1)\n","f1=f1_score(y_true,y_pred,average='weighted')\n","print(f\"F1 score:{f1}\")\n","\n","# Calculate Precision and Recall\n","precision = precision_score(y_true, y_pred, average='weighted')\n","recall = recall_score(y_true, y_pred, average='weighted')\n","\n","print(f'Precision: {precision}')\n","print(f'Recall: {recall}')\n","\n","#check the accuracy\n","lo, acc = rnn_model.evaluate([test_lyrics_data, test_artist_data], test_labels)\n","print(f'Test accuracy: {acc}')\n","print(f'Loss:{lo}')\n","#Save the model\n","rnn_model.save(\"/content/drive/MyDrive/Deep_Learning_Assignment/saved_models/RNN_new_model_lyrics_artist.h5\")\n","print(\"RNN Model saved\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-86Esb6U6GZ6","executionInfo":{"status":"ok","timestamp":1712761155348,"user_tz":-60,"elapsed":96372,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}},"outputId":"04108299-1f16-4ca0-ae2e-59eb20bf159b"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","19/19 [==============================] - 21s 993ms/step - loss: 0.8049 - accuracy: 0.6534 - val_loss: 0.8308 - val_accuracy: 0.0662\n","Epoch 2/5\n","19/19 [==============================] - 19s 1s/step - loss: 0.4087 - accuracy: 0.9171 - val_loss: 0.6599 - val_accuracy: 0.9338\n","Epoch 3/5\n","19/19 [==============================] - 18s 928ms/step - loss: 0.1553 - accuracy: 0.9950 - val_loss: 0.2971 - val_accuracy: 0.9404\n","Epoch 4/5\n","19/19 [==============================] - 17s 921ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.1726 - val_accuracy: 0.9404\n","Epoch 5/5\n","19/19 [==============================] - 19s 944ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9404\n","1/1 [==============================] - 0s 284ms/step\n","F1 score:0.21367521367521367\n","Precision: 0.14792899408284024\n","Recall: 0.38461538461538464\n","1/1 [==============================] - 0s 82ms/step - loss: 2.0851 - accuracy: 0.3846\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Test accuracy: 0.38461539149284363\n","Loss:2.085087299346924\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["RNN Model saved\n"]}]},{"cell_type":"markdown","source":["***LSTM***"],"metadata":{"id":"a7PVyQsD6IqZ"}},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/Part1_train.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/test_half.csv')\n","\n","train_df,test_df=preprocess_2(train_df,test_df)\n","train_labels,test_labels,label_encoder=encoding_2(train_df,test_df)\n","train_lyrics_data, train_artist_data, test_lyrics_data, test_artist_data, lyrics_max_length, artist_max_length, lyrics_vocab_size, artist_vocab_size=tokenizing_2(train_df, test_df)\n","\n","\n","# Define two inputs\n","lyrics_input = Input(shape=(lyrics_max_length,), dtype='int32', name='lyrics_input')\n","artist_input = Input(shape=(artist_max_length,), dtype='int32', name='artist_input')\n","\n","# Embeddings\n","lyrics_embedding = Embedding(input_dim=lyrics_vocab_size, output_dim=100, input_length=lyrics_max_length)(lyrics_input)\n","artist_embedding = Embedding(input_dim=artist_vocab_size, output_dim=100, input_length=artist_max_length)(artist_input)\n","\n","# LSTM layers\n","lyrics_lstm = LSTM(100, dropout=0.2, recurrent_dropout=0.2, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01))(lyrics_embedding)\n","artist_lstm = LSTM(100, dropout=0.2, recurrent_dropout=0.2, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01))(artist_embedding)\n","\n","# Concatenate the outputs of the two LSTMs\n","concatenated = Concatenate()([lyrics_lstm, artist_lstm])\n","\n","# Add one or more dense layers\n","dense_layer = Dense(100, activation='relu', kernel_regularizer=l2(0.01))(concatenated)\n","\n","# Output layer\n","output = Dense(len(label_encoder.classes_), activation='softmax')(dense_layer)\n","\n","# Create the model\n","lstm_model = Model(inputs=[lyrics_input, artist_input], outputs=output)\n","\n","# Compile the model\n","lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Model summary\n","lstm_model.summary()\n","\n","# Train the model\n","# Note: You need to pass a list of numpy arrays as training data: one for lyrics and one for artists\n","lstm_model.fit([train_lyrics_data, train_artist_data], train_labels, epochs=5, batch_size=32, validation_split=0.2, verbose=2)\n","\n","#find the F1 score\n","y_pred_prob=lstm_model.predict([test_lyrics_data, test_artist_data])\n","y_true=np.argmax(test_labels,axis=1)\n","y_pred=np.argmax(y_pred_prob,axis=1)\n","f1=f1_score(y_true,y_pred,average='weighted')\n","print(f\"F1 score:{f1}\")\n","\n","# Calculate Precision and Recall\n","precision = precision_score(y_true, y_pred, average='weighted')\n","recall = recall_score(y_true, y_pred, average='weighted')\n","\n","print(f'Precision: {precision}')\n","print(f'Recall: {recall}')\n","\n","#check the accuracy\n","test_loss, test_accuracy = lstm_model.evaluate([test_lyrics_data, test_artist_data], test_labels)\n","print(f'Loss:{test_loss}')\n","print(f'Test accuracy: {test_accuracy}')\n","#Save the model\n","lstm_model.save(\"/content/drive/MyDrive/Deep_Learning_Assignment/saved_models/LSTM_model_lyrics_artist.h5\")\n","print(\"LSTM Model saved\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ud4vLWcJ6Lzz","executionInfo":{"status":"ok","timestamp":1712759560197,"user_tz":-60,"elapsed":338003,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}},"outputId":"599bd6d5-8b89-4559-f9c8-768657ffe2eb"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model_4\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," lyrics_input (InputLayer)   [(None, 868)]                0         []                            \n","                                                                                                  \n"," artist_input (InputLayer)   [(None, 3)]                  0         []                            \n","                                                                                                  \n"," embedding_12 (Embedding)    (None, 868, 100)             764500    ['lyrics_input[0][0]']        \n","                                                                                                  \n"," embedding_13 (Embedding)    (None, 3, 100)               1400      ['artist_input[0][0]']        \n","                                                                                                  \n"," lstm_3 (LSTM)               (None, 100)                  80400     ['embedding_12[0][0]']        \n","                                                                                                  \n"," lstm_4 (LSTM)               (None, 100)                  80400     ['embedding_13[0][0]']        \n","                                                                                                  \n"," concatenate_4 (Concatenate  (None, 200)                  0         ['lstm_3[0][0]',              \n"," )                                                                   'lstm_4[0][0]']              \n","                                                                                                  \n"," dense_17 (Dense)            (None, 100)                  20100     ['concatenate_4[0][0]']       \n","                                                                                                  \n"," dense_18 (Dense)            (None, 3)                    303       ['dense_17[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 947103 (3.61 MB)\n","Trainable params: 947103 (3.61 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n","Epoch 1/5\n","19/19 - 77s - loss: 6.1588 - accuracy: 0.7612 - val_loss: 4.7009 - val_accuracy: 0.0596 - 77s/epoch - 4s/step\n","Epoch 2/5\n","19/19 - 60s - loss: 3.7256 - accuracy: 0.6633 - val_loss: 2.8348 - val_accuracy: 0.9404 - 60s/epoch - 3s/step\n","Epoch 3/5\n","19/19 - 59s - loss: 2.2325 - accuracy: 0.9652 - val_loss: 1.8104 - val_accuracy: 0.9404 - 59s/epoch - 3s/step\n","Epoch 4/5\n","19/19 - 60s - loss: 1.2839 - accuracy: 0.9668 - val_loss: 1.0568 - val_accuracy: 0.9404 - 60s/epoch - 3s/step\n","Epoch 5/5\n","19/19 - 60s - loss: 0.8064 - accuracy: 0.9668 - val_loss: 0.7145 - val_accuracy: 0.9404 - 60s/epoch - 3s/step\n","1/1 [==============================] - 1s 609ms/step\n","F1 score:0.21367521367521367\n","Precision: 0.14792899408284024\n","Recall: 0.38461538461538464\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 252ms/step - loss: 2.0422 - accuracy: 0.3846\n","Loss:2.04223370552063\n","Test accuracy: 0.38461539149284363\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["LSTM Model saved\n"]}]},{"cell_type":"markdown","source":["***CNN***"],"metadata":{"id":"Owa2bcvA6PAZ"}},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/Part1_train.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/test_half.csv')\n","\n","train_df,test_df=preprocess_2(train_df,test_df)\n","train_labels,test_labels,label_encoder=encoding_2(train_df,test_df)\n","train_lyrics_data, train_artist_data, test_lyrics_data, test_artist_data, lyrics_max_length, artist_max_length, lyrics_vocab_size, artist_vocab_size=tokenizing_2(train_df, test_df)\n","\n","# Inputs\n","lyrics_input = Input(shape=(lyrics_max_length,), dtype='int32', name='lyrics_input')\n","artist_input = Input(shape=(artist_max_length,), dtype='int32', name='artist_input')\n","\n","# Embeddings\n","lyrics_embedding = Embedding(input_dim=lyrics_vocab_size, output_dim=100, input_length=lyrics_max_length)(lyrics_input)\n","artist_embedding = Embedding(input_dim=artist_vocab_size, output_dim=100, input_length=artist_max_length)(artist_input)\n","\n","\n","# CNN layers for each input\n","lyrics_cnn = Conv1D(filters=128, kernel_size=5, activation='relu')(lyrics_embedding)\n","lyrics_pooling = GlobalMaxPooling1D()(lyrics_cnn)\n","artist_cnn = Conv1D(filters=128, kernel_size=3, activation='relu')(artist_embedding)\n","artist_pooling = GlobalMaxPooling1D()(artist_cnn)\n","\n","# Concatenate the outputs of the two CNN paths\n","concatenated = Concatenate()([lyrics_pooling, artist_pooling])\n","\n","# Dense layers\n","dense_layer = Dense(units=10, activation='relu')(concatenated)\n","\n","# Output layer\n","output = Dense(units=len(label_encoder.classes_), activation='softmax')(dense_layer)\n","\n","# Create the model\n","cnn_model = Model(inputs=[lyrics_input, artist_input], outputs=output)\n","\n","# Compile the model\n","cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Model summary\n","cnn_model.summary()\n","\n","# Train the model\n","cnn_model.fit([train_lyrics_data, train_artist_data], train_labels, epochs=5, batch_size=32, validation_split=0.2, verbose=2)\n","#find the F1 score\n","y_pred_prob=cnn_model.predict([test_lyrics_data, test_artist_data])\n","y_pred=np.argmax(y_pred_prob,axis=1)\n","y_true=np.argmax(test_labels,axis=1)\n","f1=f1_score(y_true,y_pred,average='weighted')\n","print(f\"F1 score:{f1}\")\n","\n","# Calculate Precision and Recall\n","precision = precision_score(y_true, y_pred, average='weighted')\n","recall = recall_score(y_true, y_pred, average='weighted')\n","\n","print(f'Precision: {precision}')\n","print(f'Recall: {recall}')\n","\n","#check the accuracy\n","test_loss, test_accuracy = cnn_model.evaluate([test_lyrics_data, test_artist_data], test_labels)\n","print(f'Test accuracy: {test_accuracy}')\n","print(f'Loss:{test_loss}')\n","#save the model\n","cnn_model.save(\"/content/drive/MyDrive/Deep_Learning_Assignment/saved_models/CNN_model_lyrics_artist.h5\")\n","print(\"CNN Model saved\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ubDPfWmK6SQz","executionInfo":{"status":"ok","timestamp":1712761333091,"user_tz":-60,"elapsed":15868,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}},"outputId":"2bea7a71-9fef-474e-81f9-d250239f3895"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_6\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," lyrics_input (InputLayer)   [(None, 868)]                0         []                            \n","                                                                                                  \n"," artist_input (InputLayer)   [(None, 3)]                  0         []                            \n","                                                                                                  \n"," embedding_19 (Embedding)    (None, 868, 100)             764500    ['lyrics_input[0][0]']        \n","                                                                                                  \n"," embedding_20 (Embedding)    (None, 3, 100)               1400      ['artist_input[0][0]']        \n","                                                                                                  \n"," conv1d_4 (Conv1D)           (None, 864, 128)             64128     ['embedding_19[0][0]']        \n","                                                                                                  \n"," conv1d_5 (Conv1D)           (None, 1, 128)               38528     ['embedding_20[0][0]']        \n","                                                                                                  \n"," global_max_pooling1d_4 (Gl  (None, 128)                  0         ['conv1d_4[0][0]']            \n"," obalMaxPooling1D)                                                                                \n","                                                                                                  \n"," global_max_pooling1d_5 (Gl  (None, 128)                  0         ['conv1d_5[0][0]']            \n"," obalMaxPooling1D)                                                                                \n","                                                                                                  \n"," concatenate_6 (Concatenate  (None, 256)                  0         ['global_max_pooling1d_4[0][0]\n"," )                                                                  ',                            \n","                                                                     'global_max_pooling1d_5[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," dense_24 (Dense)            (None, 10)                   2570      ['concatenate_6[0][0]']       \n","                                                                                                  \n"," dense_25 (Dense)            (None, 3)                    33        ['dense_24[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 871159 (3.32 MB)\n","Trainable params: 871159 (3.32 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n","Epoch 1/5\n","19/19 - 6s - loss: 0.8801 - accuracy: 0.5108 - val_loss: 0.6006 - val_accuracy: 0.9404 - 6s/epoch - 314ms/step\n","Epoch 2/5\n","19/19 - 2s - loss: 0.3888 - accuracy: 0.9668 - val_loss: 0.2978 - val_accuracy: 0.9404 - 2s/epoch - 102ms/step\n","Epoch 3/5\n","19/19 - 3s - loss: 0.1031 - accuracy: 0.9668 - val_loss: 0.0841 - val_accuracy: 0.9404 - 3s/epoch - 155ms/step\n","Epoch 4/5\n","19/19 - 2s - loss: 0.0462 - accuracy: 0.9668 - val_loss: 0.0773 - val_accuracy: 0.9404 - 2s/epoch - 86ms/step\n","Epoch 5/5\n","19/19 - 2s - loss: 0.0393 - accuracy: 0.9668 - val_loss: 0.0759 - val_accuracy: 0.9404 - 2s/epoch - 99ms/step\n","1/1 [==============================] - 0s 80ms/step\n","F1 score:0.14479638009049772\n","Precision: 0.09467455621301776\n","Recall: 0.3076923076923077\n","1/1 [==============================] - 0s 27ms/step - loss: 2.2336 - accuracy: 0.3077\n","Test accuracy: 0.3076923191547394\n","Loss:2.2335703372955322\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["CNN Model saved\n"]}]},{"cell_type":"markdown","source":["***Embedding on the fly***"],"metadata":{"id":"3ArEp8A_6UnJ"}},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/Part1_train.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/test_half.csv')\n","\n","train_df,test_df=preprocess_2(train_df,test_df)\n","train_labels,test_labels,label_encoder=encoding_2(train_df,test_df)\n","train_lyrics_data, train_artist_data, test_lyrics_data, test_artist_data, lyrics_max_length, artist_max_length, lyrics_vocab_size, artist_vocab_size=tokenizing_2(train_df, test_df)\n","\n","embedding_dims=50\n","# Define model parameters\n","lyrics_input = Input(shape=(lyrics_max_length,), dtype='int32', name='lyrics_input')\n","artist_input = Input(shape=(artist_max_length,), dtype='int32', name='artist_input')\n","\n","# Embedding layers\n","lyrics_embedding = Embedding(input_dim=lyrics_vocab_size, output_dim=embedding_dims, input_length=lyrics_max_length)(lyrics_input)\n","artist_embedding = Embedding(input_dim=artist_vocab_size, output_dim=embedding_dims, input_length=artist_max_length)(artist_input)\n","\n","# Flatten the embeddings\n","lyrics_flatten = Flatten()(lyrics_embedding)\n","artist_flatten = Flatten()(artist_embedding)\n","\n","# Concatenate the flattened outputs\n","concatenated = Concatenate()([lyrics_flatten, artist_flatten])\n","\n","# Dense layers\n","dense_layer = Dense(200, activation='relu')(concatenated)\n","output = Dense(len(label_encoder.classes_), activation='softmax')(dense_layer)\n","\n","# Create the model\n","emb_model = Model(inputs=[lyrics_input, artist_input], outputs=output)\n","\n","# Compile the model\n","emb_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Model summary\n","emb_model.summary()\n","\n","# Train the model\n","emb_model.fit([train_lyrics_data, train_artist_data], train_labels, batch_size=32, epochs=4, validation_split=0.2)\n","\n","\n","#find the F1 score\n","y_pred_prob=emb_model.predict([test_lyrics_data, test_artist_data])\n","y_pred=np.argmax(y_pred_prob,axis=1)\n","y_true=np.argmax(test_labels,axis=1)\n","f1=f1_score(y_true,y_pred,average='weighted')\n","print(f\"F1 score:{f1}\")\n","\n","# Calculate Precision and Recall\n","precision = precision_score(y_true, y_pred, average='weighted')\n","recall = recall_score(y_true, y_pred, average='weighted')\n","\n","print(f'Precision: {precision}')\n","print(f'Recall: {recall}')\n","\n","#check the accuracy\n","test_loss, test_accuracy = emb_model.evaluate([test_lyrics_data, test_artist_data], test_labels)\n","print(f'Test accuracy: {test_accuracy}')\n","print(f'Loss:{test_loss}')\n","\n","#Save the model\n","emb_model.save(\"/content/drive/MyDrive/Deep_Learning_Assignment/saved_models/emb_model_lyrics_artist.h5\")\n","print(\"Embedding on the fly Model saved\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YPZnKPgE6YXi","executionInfo":{"status":"ok","timestamp":1712761390214,"user_tz":-60,"elapsed":24871,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}},"outputId":"a0a07fab-a8cf-4816-b02a-4659d89aed79"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_7\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," lyrics_input (InputLayer)   [(None, 868)]                0         []                            \n","                                                                                                  \n"," artist_input (InputLayer)   [(None, 3)]                  0         []                            \n","                                                                                                  \n"," embedding_21 (Embedding)    (None, 868, 50)              382250    ['lyrics_input[0][0]']        \n","                                                                                                  \n"," embedding_22 (Embedding)    (None, 3, 50)                700       ['artist_input[0][0]']        \n","                                                                                                  \n"," flatten_3 (Flatten)         (None, 43400)                0         ['embedding_21[0][0]']        \n","                                                                                                  \n"," flatten_4 (Flatten)         (None, 150)                  0         ['embedding_22[0][0]']        \n","                                                                                                  \n"," concatenate_7 (Concatenate  (None, 43550)                0         ['flatten_3[0][0]',           \n"," )                                                                   'flatten_4[0][0]']           \n","                                                                                                  \n"," dense_26 (Dense)            (None, 200)                  8710200   ['concatenate_7[0][0]']       \n","                                                                                                  \n"," dense_27 (Dense)            (None, 3)                    603       ['dense_26[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 9093753 (34.69 MB)\n","Trainable params: 9093753 (34.69 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n","Epoch 1/4\n","19/19 [==============================] - 5s 146ms/step - loss: 1.0336 - accuracy: 0.5406 - val_loss: 0.5461 - val_accuracy: 0.9404\n","Epoch 2/4\n","19/19 [==============================] - 2s 124ms/step - loss: 0.3362 - accuracy: 0.9436 - val_loss: 0.5444 - val_accuracy: 0.8411\n","Epoch 3/4\n","19/19 [==============================] - 3s 150ms/step - loss: 0.0953 - accuracy: 0.9934 - val_loss: 0.4500 - val_accuracy: 0.8675\n","Epoch 4/4\n","19/19 [==============================] - 3s 125ms/step - loss: 0.0342 - accuracy: 0.9983 - val_loss: 0.3781 - val_accuracy: 0.8874\n","1/1 [==============================] - 0s 104ms/step\n","F1 score:0.18099547511312217\n","Precision: 0.1282051282051282\n","Recall: 0.3076923076923077\n","1/1 [==============================] - 0s 36ms/step - loss: 2.2207 - accuracy: 0.3077\n","Test accuracy: 0.3076923191547394\n","Loss:2.2207345962524414\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Embedding on the fly Model saved\n"]}]},{"cell_type":"markdown","source":["***Pretrained word embedding***"],"metadata":{"id":"ApyQisKQ6ckf"}},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/Part1_train.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Assignment/dataset/Multilingual/test_half.csv')\n","\n","train_df,test_df=preprocess_2(train_df,test_df)\n","train_labels,test_labels,label_encoder=encoding_2(train_df,test_df)\n","train_lyrics_data, train_artist_data, test_lyrics_data, test_artist_data, lyrics_max_length, artist_max_length, lyrics_vocab_size, artist_vocab_size=tokenizing_2(train_df, test_df)\n","\n","\n","word2vec_path = '/content/drive/MyDrive/Deep_Learning_Assignment/saved_models/GoogleNews-vectors-negative300.bin'  # Example for the same directory; adjust as needed\n","word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n","#def document_vector(word2vec_model, doc):\n","#    doc = [word for word in doc.split() if word in word2vec_model.key_to_index]\n","#    if not doc:\n","#        return np.zeros(word2vec_model.vector_size)\n","#    return np.mean(word2vec_model[doc], axis=0)\n","\n","train_df['vec'] = train_df['Lyrics'].apply(lambda x: document_vector(word2vec, x))\n","test_df['vec']=test_df[\"Lyrics\"].apply(lambda x: document_vector(word2vec, x))\n","\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# Initialize the OneHotEncoder\n","encoder = OneHotEncoder(sparse=False,handle_unknown=\"ignore\")  # Ensure output is a dense matrix\n","\n","# Fit and transform the artist names\n","# Reshape(-1, 1) is used to convert the series into a shape that OneHotEncoder expects: a 2D array\n","artist_train_encoded = encoder.fit_transform(train_df[['Artist']].values.reshape(-1, 1))\n","artist_test_encoded = encoder.transform(test_df[['Artist']].values.reshape(-1, 1))\n","\n","X = np.array(train_df['vec'].tolist())\n","y = np.array(test_df['vec'].tolist())\n","\n","X_combined=np.concatenate([X, artist_train_encoded], axis=1)\n","y_combined=np.concatenate([y, artist_test_encoded], axis=1)\n","input_shape = X_combined.shape[1]\n","\n","\n","pre_model = Sequential()\n","#No need for an embedding layer\n","pre_model.add(Dense(200, activation='relu',input_shape=(input_shape,)))\n","pre_model.add(Dense(3,activation='softmax'))\n","\n","pre_model.summary()\n","\n","pre_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n","\n","pre = pre_model.fit(X_combined, train_labels,batch_size=32,epochs=4,validation_split=0.2)\n","\n","#find the F1 score\n","y_pred_prob=pre_model.predict(y_combined)\n","y_pred=np.argmax(y_pred_prob,axis=1)\n","y_true=np.argmax(test_labels,axis=1)\n","f1=f1_score(y_true,y_pred,average='weighted')\n","print(f\"F1 score:{f1}\")\n","\n","# Calculate Precision and Recall\n","precision = precision_score(y_true, y_pred, average='weighted')\n","recall = recall_score(y_true, y_pred, average='weighted')\n","\n","print(f'Precision: {precision}')\n","print(f'Recall: {recall}')\n","\n","#check the accuracy\n","test_loss, test_accuracy = pre_model.evaluate(y_combined, test_labels)\n","print(f'Test accuracy: {test_accuracy}')\n","print(f'Loss:{test_loss}')\n","\n","#Save the model\n","pre_model.save(\"/content/drive/MyDrive/Deep_Learning_Assignment/saved_models/pre_model_Lyrics_Artist.h5\")\n","print(\"Pretrained word Model saved\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s8DNlQ2H6iWr","executionInfo":{"status":"ok","timestamp":1712761463467,"user_tz":-60,"elapsed":41385,"user":{"displayName":"Madhuri Sawant","userId":"00395898343135630121"}},"outputId":"afd796f7-b9b9-4c31-e0d8-6399dbb90679"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_9\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_28 (Dense)            (None, 200)               61600     \n","                                                                 \n"," dense_29 (Dense)            (None, 3)                 603       \n","                                                                 \n","=================================================================\n","Total params: 62203 (242.98 KB)\n","Trainable params: 62203 (242.98 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/4\n","19/19 [==============================] - 1s 13ms/step - loss: 0.8017 - accuracy: 0.8425 - val_loss: 0.6162 - val_accuracy: 0.9404\n","Epoch 2/4\n","19/19 [==============================] - 0s 6ms/step - loss: 0.4862 - accuracy: 0.9668 - val_loss: 0.4199 - val_accuracy: 0.9470\n","Epoch 3/4\n","19/19 [==============================] - 0s 6ms/step - loss: 0.3293 - accuracy: 0.9668 - val_loss: 0.2994 - val_accuracy: 0.9536\n","Epoch 4/4\n","19/19 [==============================] - 0s 5ms/step - loss: 0.2198 - accuracy: 0.9668 - val_loss: 0.1794 - val_accuracy: 0.9536\n","1/1 [==============================] - 0s 42ms/step\n","F1 score:0.15384615384615385\n","Precision: 0.10256410256410256\n","Recall: 0.3076923076923077\n","1/1 [==============================] - 0s 24ms/step - loss: 1.4008 - accuracy: 0.3077\n","Test accuracy: 0.3076923191547394\n","Loss:1.4007920026779175\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Pretrained word Model saved\n"]}]}]}